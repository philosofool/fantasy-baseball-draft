{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft Prep\n",
    "\n",
    "Lots prepare csv files for draft activity. Also prepare weighted csv files for other uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from functools import partial\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import re\n",
    "from collections.abc import Callable, Iterable, Mapping\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from philosofool.data_sources.utils import read_yml  # type: ignore\n",
    "from philosofool.data_science.graph import MetricGraph\n",
    "from fantasy_baseball_draft.utils import StatSynonyms, load_cbs_data, DataLoader\n",
    "from fantasy_baseball_draft.utils import cbs_player_col_to_df\n",
    "from fantasy_baseball_draft.stats import StatCalculator\n",
    "\n",
    "data_path = read_yml('local/config.yml')['paths']['local_data']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID Functions\n",
    "\n",
    "Why is this so complicated? We need to join players expected to play in the current year with Fangraphs ID data to create a unique ID column for merging.\n",
    "TL;DR: we're working with disjoint lists to make it all work.\n",
    "Historical data solves this problem simply for players who have played.\n",
    "But there are players expected who did not appear in the previous year.\n",
    "For those, the name of the player is helpful for the merging.\n",
    "But the result is that we need (1) a dataset of historical MLB play and (2) some preseason projections.\n",
    "The players "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitching_metrics = ['ERA', 'WHIP', 'W', 'S', 'K']\n",
    "hitting_metrics = ['R', 'HR', 'RBI', 'SB', 'BA']\n",
    "scoring_metrics = pitching_metrics + hitting_metrics\n",
    "\n",
    "class AssociatePlayers:\n",
    "    \"\"\"Associate entities from different datasets.\n",
    "\n",
    "    Given two dataframes that share entities but not a common single\n",
    "    join key, this can construct a merge of the data based on columns\n",
    "    that are assumed to find unique one.\n",
    "\n",
    "    Example: Given dataframes of pitchers in 2019 that use different\n",
    "    naming conventions ('Mike', 'Michael', etc.) we can align these by\n",
    "    assuming that two pitchers are the same if they started the same\n",
    "    number of games, had the same number of walks, hits and strikeouts.\n",
    "    \"\"\"\n",
    "    synonyms = StatSynonyms()\n",
    "\n",
    "    def associate(self, df1: pd.DataFrame, df2: pd.DataFrame, index_cols: list) -> pd.DataFrame:\n",
    "        if df1.duplicated().sum():\n",
    "            warnings.warn(\"Found duplicated in df1.\")\n",
    "        if df2.duplicated().sum():\n",
    "            warnings.warn(\"Found duplicated in df2.\")\n",
    "        df1 = self.synonyms.normalize_df(df1)\n",
    "        df2 = self.synonyms.normalize_df(df2)\n",
    "        df = df1.set_index(index_cols).merge(df2.set_index(index_cols), left_index=True, right_index=True)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_on_name(cbs: pd.DataFrame, fg: pd.DataFrame) -> pd.DataFrame:\n",
    "    cbs_player = (\n",
    "        cbs_player_col_to_df(cbs.Player) #.Team.fillna('---').unique().tolist()\n",
    "        .merge(cbs[['Player']], left_index=True, right_index=True)\n",
    "        .merge(fg[['Name', 'playerid']], on='Name', how='left')\n",
    "    )\n",
    "    return cbs_player\n",
    "\n",
    "def map_cbs_player_col_to_id_by_name(cbs: pd.DataFrame, fg: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Use cbs \"Player\" field to return series of CBS player names to fg player ids.\"\"\"\n",
    "    df = merge_on_name(cbs, fg).drop_duplicates(subset=['playerid'], keep=False)\n",
    "    playerid = df.playerid\n",
    "    ids = df.set_index('Player').playerid.dropna().astype(str)\n",
    "    return ids.where(ids.str.startswith('sa'), ids.str.strip('sa').astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_id_map(df: pd.DataFrame, fg_df: pd.DataFrame, ids: pd.Series) -> pd.Series:\n",
    "    \"\"\"Map cbs Player column to fg ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df:\n",
    "        CBS data.\n",
    "    fg_df:\n",
    "        Fangraphs data.\n",
    "    ids:\n",
    "        Mapping of Player:fg_id; this is a mapping of known cases.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['playerid'] = df.Player.map(ids).fillna(-1)\n",
    "    name_ids = map_cbs_player_col_to_id_by_name(df[df.playerid == -1], fg_df)\n",
    "    name_ids = name_ids[~name_ids.duplicated()]\n",
    "    ids = pd.concat([ids, name_ids]).to_dict()\n",
    "    return df.Player.map(ids).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_id_map_from_stat_associations(cbs, fg, index_cols, duplicated=False) -> pd.Series:\n",
    "    \"\"\"Return series mapping CBS player \"Player\" column to a fangraphs ID column.\"\"\"\n",
    "    cbs_with_playtime = cbs[cbs[index_cols].sum(axis=1) > 0]\n",
    "    n_players_with_pt = len(cbs_with_playtime)\n",
    "    if duplicated:\n",
    "        return cbs_with_playtime[cbs_with_playtime.duplicated(subset=index_cols, keep=False)]\n",
    "    cbs_with_playtime = cbs_with_playtime.drop_duplicates(subset=index_cols, keep=False)\n",
    "    print(f\"Dropped {n_players_with_pt - len(cbs_with_playtime)} duplicated records.\")\n",
    "\n",
    "    cbs_to_fg = AssociatePlayers().associate(cbs_with_playtime, fg, index_cols)\n",
    "    cbs_to_fg.Player = cbs_to_fg.Player.str.strip()\n",
    "    as_dict = dict(zip(cbs_to_fg.Player.str.strip(), cbs_to_fg.playerid))\n",
    "    return pd.Series(as_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Fangraphs Player Id to CBS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitter_match = ['AB', 'H', 'BB', 'RBI', 'K']\n",
    "pitcher_match = ['IP', 'W', 'G', 'K', 'H', 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = read_yml('local/config.yml')['paths']['local_data']\n",
    "hist_path = os.path.join(data_path, 'historical')\n",
    "loader = DataLoader(hist_path)\n",
    "\n",
    "pitcher_ids = _build_id_map_from_stat_associations(\n",
    "    loader.load_cbs_csv('cbs_pitchers_2023.csv'),\n",
    "    loader.load_csv('fg_pitchers_2023.csv'), pitcher_match\n",
    ")\n",
    "\n",
    "hitter_ids = _build_id_map_from_stat_associations(\n",
    "    loader.load_cbs_csv('cbs_hitters_2023.csv'),\n",
    "    loader.load_csv('fg_hitters_2023.csv'), hitter_match\n",
    ")\n",
    "#build_id_map('cbs_hitters_2022.csv', 'fg_hitters_2022.csv', ['H', 'BB', 'RBI', 'K'], True)\n",
    "#{k: v for k, v in hitter_ids.items() if 'Franc' in k}# [hitter_ids..str.contains('Franc')]\n",
    "hitter_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_stats(df1, df2, stats: list[str]) -> dict:\n",
    "    \"\"\"Combine stats from two dataframes.\"\"\"\n",
    "    # stat_calculator = StatCalculator()\n",
    "    # df1 = stat_calculator.add_metrics(df1, stats)\n",
    "    # df2 = stat_calculator.add_metrics(df2, stats)\n",
    "\n",
    "    shared_idx = df2.index.intersection(df1.index)\n",
    "    df1_idx = df1.index.difference(shared_idx)\n",
    "    df2_idx = df2.index.difference(shared_idx)\n",
    "\n",
    "    return {\n",
    "        stat: pd.concat([\n",
    "            (df1.loc[shared_idx, stat] + df2.loc[shared_idx, stat]) / 2,\n",
    "            df1.loc[df1_idx, stat],\n",
    "            df2.loc[df2_idx, stat]\n",
    "        ])\n",
    "        for stat in stats\n",
    "    }\n",
    "\n",
    "# cbs_hitter_proj.assign(**weight_stats(cbs_hitter_proj, fg_hitter_proj, ['PA', 'AB', 'BB', 'H', 'HR', 'K', 'RBI', 'R', 'BA', 'SB']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elig = DataLoader(os.path.join(data_path, 'eligibility')).load_cbs_csv('eligibility.csv')\n",
    "projections = DataLoader(os.path.join(data_path, 'projections/2024'))\n",
    "fg_hitter_proj = projections.load_csv('fg_depth_hitters.csv')\n",
    "fg_pitcher_proj = projections.load_csv('fg_depth_pitchers.csv')\n",
    "\n",
    "cbs_hitter_proj = (\n",
    "    projections\n",
    "    .load_cbs_csv('cbs_hitters.csv')\n",
    "    .assign(\n",
    "        playerid=lambda df: build_id_map(df, fg_hitter_proj, hitter_ids),\n",
    "        PA=lambda df: df.AB + df.BB\n",
    "    )\n",
    "    .merge(elig[[\"Player\", \"Eligible\"]], how='left', on=\"Player\")\n",
    ")\n",
    "\n",
    "cbs_pitchers_proj = (\n",
    "    projections\n",
    "    .load_cbs_csv('cbs_pitchers.csv')\n",
    "    .assign(\n",
    "        playerid=lambda df: build_id_map(df, fg_pitcher_proj, pitcher_ids),\n",
    "        ER=lambda df: df.ERA * df.IP / 9\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_pitchers_proj.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_hitter_proj.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def standings_html_to_df(standings: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    stat_standings = []\n",
    "    for df in standings:\n",
    "        metrics = StatCalculator().metrics\n",
    "        for i, row in df.iterrows():\n",
    "            if row.loc[0] == 'Team':\n",
    "                idx = i\n",
    "                break\n",
    "        stat_standings.append(df.loc[i + 1:, 0:1].rename(columns=df.loc[i]))\n",
    "    standings = functools.reduce(lambda a, b: a.merge(b, on='Team'), stat_standings)\n",
    "    return standings.astype({col: float for col in standings.columns if col != 'Team'})\n",
    "\n",
    "\n",
    "standings = standings_html_to_df(pd.read_html(os.path.join(data_path, 'standings/klf_2023.html'))[5:])\n",
    "\n",
    "\n",
    "def weighted_ratio(x: ArrayLike, weight: ArrayLike, median: ArrayLike):\n",
    "    return weight * (x - median)\n",
    "\n",
    "def model_spg(arr: np.ndarray|pd.Series, low_better=False) -> Callable[[ArrayLike], np.ndarray]:\n",
    "    \"\"\"Calculate a linear regression for spg weights and return a function that applies it.\"\"\"\n",
    "    if isinstance(arr, pd.Series):\n",
    "        arr = arr.values\n",
    "    arr = arr.reshape(-1, 1)\n",
    "    points = rankdata(arr * -1) if low_better else rankdata(arr)\n",
    "    slope = LinearRegression().fit(arr, points).coef_[0]\n",
    "\n",
    "    def spg_value(x: ArrayLike) -> np.ndarray:\n",
    "        return x * slope\n",
    "\n",
    "    return spg_value\n",
    "\n",
    "\n",
    "spg_model = MetricGraph.from_model({\n",
    "    # 'IP': (lambda _: 1200., ('ERA',)),\n",
    "    # 'AB': (lambda _: 5600., ('BA',)),\n",
    "    'median_ERA': (np.median, ('ERA',)),\n",
    "    'median_WHIP': (np.median, ('WHIP',)),\n",
    "    'median_BA': (np.median, ('BA',)),\n",
    "    'xER': (weighted_ratio, ('ERA', 'IP', 'median_ERA')),\n",
    "    'xWHIP': (weighted_ratio, ('WHIP', 'IP', 'median_WHIP')),\n",
    "    'xH': (weighted_ratio, ('BA', 'AB', 'median_BA')),\n",
    "    'W_spg': (model_spg, ('W',)),\n",
    "    'S_spg': (model_spg, ('S',)),\n",
    "    'K_spg': (model_spg, ('K',)),\n",
    "    'ERA_spg': (partial(model_spg, low_better=True), ('xER',)),\n",
    "    'WHIP_spg': (partial(model_spg, low_better=True), ('xWHIP',)),\n",
    "    'R_spg': (model_spg, ('R',)),\n",
    "    'HR_spg': (model_spg, ('HR',)),\n",
    "    'RBI_spg': (model_spg, ('RBI',)),\n",
    "    'SB_spg': (model_spg, ('SB',)),\n",
    "    'BA_spg': (model_spg, ('xH',)),\n",
    "})\n",
    "\n",
    "def extract_model(df: pd.DataFrame, metric_graph: MetricGraph, metrics: Iterable) -> MetricGraph:\n",
    "    calculated_model = metric_graph.calculate_metrics(df, metrics)\n",
    "    model_graph = {metric: metric_graph.dependency_graph[metric] for metric in metrics}\n",
    "    model_fns = {metric: calculated_model[metric] for metric in metrics}\n",
    "    return MetricGraph(model_graph, model_fns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spg_names = [f'{metric}_spg' for metric in pitching_metrics + hitting_metrics]\n",
    "\n",
    "fwar_model = {\n",
    "    'pitcher_fWAR': (StatCalculator.reduce_sum, tuple(f'{metric}_spg' for metric in pitching_metrics)),\n",
    "    'hitter_fWAR': (StatCalculator.reduce_sum, ('R_spg', 'RBI_spg', 'HR_spg', 'BA_spg', 'SB_spg'))\n",
    "}\n",
    "\n",
    "fantasy_stat_model = StatCalculator.from_model(\n",
    "    extract_model(standings.assign(AB=lambda _: 5600, IP=lambda _: 1200), spg_model, spg_names).model()\n",
    "    | spg_model.model(['xER', 'xH', 'xWHIP'])\n",
    "    | fwar_model\n",
    ")\n",
    "median_stats = spg_model.calculate_metrics(standings, ['median_BA', 'median_ERA', 'median_WHIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_stat_model.add_metrics(cbs_hitter_proj.assign(median_BA=lambda _: median_stats['median_BA']), metrics=['HR_spg', 'BA_spg', 'hitter_fWAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{1: 2} | {3: 4} | {1: 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fantasy_stat_model.get_metric_dependencies(['hitter_fWAR']))\n",
    "#fantasy_stat_model.add_metrics(cbs_hitter_proj, ['hitter_fWAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_value(hitter_fwar: ArrayLike, eligible: ArrayLike, pos: str, n_rostered: int) -> float:\n",
    "    eligible_idx = np.nonzero(matches_eligible(eligible, pos))\n",
    "    best = np.argpartition(hitter_fwar[eligible_idx], kth=n_rostered)[-n_rostered:]\n",
    "    return np.min(best)\n",
    "\n",
    "def matches_eligbible(eligbible: ArrayLike, pos: str) -> np.ndarray:\n",
    "    elig_series = pd.Series(eligbible)\n",
    "    pattern = f'^{pos}$|,{pos},|^{pos},|,{pos}$'\n",
    "    clean_elig = elig_series.str.replace(r'\\s', '', regex=True)\n",
    "    return clean_elig.str.contains(pattern, regex=True)\n",
    "\n",
    "def test_matches_eligible():\n",
    "    \"\"\"Test of matches_eligible.\"\"\"\n",
    "    eligible = ['C', 'C, CF', '1B, C', '1B, C, SS', 'CF', 'SS']\n",
    "    result = matches_eligbible(eligible, 'C')\n",
    "    assert np.array_equal(result, [True, True, True, True, False, False])\n",
    "\n",
    "test_matches_eligible()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think everything below this needs to be jettisoned.\n",
    "# Current state of above allows calculation of everything except replacement level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fg(cbs, base_path, cols, name_filter=lambda x: x):\n",
    "    # WTF is this mess of shit.\n",
    "    cbs = cbs.copy()\n",
    "    ids = cbs.playerid.to_numpy()\n",
    "    loader = DataLoader(base_path)\n",
    "    for path in os.listdir(base_path):\n",
    "        if name_filter(path) and 'cbs' not in path:\n",
    "            #print(path)\n",
    "            suffixes = ('', '_' + path[:5].strip('_'))\n",
    "            df = loader.load_csv(path)\n",
    "            if len(df) == 0:\n",
    "                #print(f'{path} data is empty...')\n",
    "                continue\n",
    "            #print(df.columns, df.playerid[:10])\n",
    "            df = df[~df.playerid.astype(str).str.startswith('sa')]\n",
    "\n",
    "            df.playerid = df.playerid.astype(int)\n",
    "            df = df[df.playerid.isin(list(ids))]\n",
    "            assert len(df) > 0, 'df empty, which is sort of like wdf?'\n",
    "            cbs = cbs.merge(df[cols], on='playerid', suffixes=suffixes, how='left')\n",
    "    return cbs\n",
    "\n",
    "def merge_fg_hitters(cbs, base_path):\n",
    "    cols = ['playerid', 'PA',  'AB', 'H', 'HR', 'R', 'RBI', 'SB']\n",
    "    return merge_fg(cbs, base_path, cols, lambda x: 'hitter' in x)\n",
    "\n",
    "def merge_fg_pitchers(cbs, base_path):\n",
    "    cols = ['playerid', 'IP', 'ER', 'WHIP', 'K', 'S', 'W']\n",
    "    return merge_fg(cbs, base_path, cols, lambda x: 'pitch' in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weighted_stats(df, stats, playtime_stat):\n",
    "    df = df.copy()\n",
    "    pt = playtime_stat\n",
    "    suffixes = set(['_'.join(col.split('_')[1:]) for col in df.columns if len(col.split('_')) > 1])\n",
    "    assert (f'{pt}_fg-de' in df.columns), f\"{pt} not in fg-de columns. Something is wrong.\"\n",
    "    df[f'{pt}_adj'] = (df[f'{pt}_fg-de'] + df[pt]) / 2\n",
    "\n",
    "    for suf in suffixes:\n",
    "        for col in stats:\n",
    "            df[f'{col}_{suf}'] = df[f'{col}_{suf}'] / df[f'{pt}_{suf}'] * df[f'{pt}_adj']\n",
    "    for col in stats:\n",
    "        adj_cols = [col] + [c for c in df.columns if re.match(f'{col}_', c)]\n",
    "        df[f'{col}_adj'] = (df[adj_cols].sum(axis=1) / df[adj_cols].notna().sum(axis=1))\n",
    "    return df\n",
    "\n",
    "#add_weighted_stats(cbs_hitters, cols[2:], 'PA')\n",
    "hitter_stats = ['playerid', 'PA',  'AB', 'H', 'HR', 'R', 'RBI', 'SB']\n",
    "pitcher_stats = ['playerid', 'IP', 'ER', 'WHIP', 'K', 'S', 'W']\n",
    "full_hitters = (cbs_hitter_proj\n",
    "    .pipe(merge_fg_hitters, data_path + '/projections')\n",
    "    .pipe(add_weighted_stats, hitter_stats[2:], 'PA')\n",
    "    )\n",
    "full_pitchers = (cbs_pitchers_proj\n",
    "    .pipe(merge_fg_pitchers, data_path + '/projections')\n",
    "    .pipe(add_weighted_stats, pitcher_stats[2:], 'IP')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fantasy_baseball_draft.spg import FantasyValuator, spgs_from_standings_html\n",
    "\n",
    "valuator = FantasyValuator(spgs_from_standings_html(os.path.join(data_path, 'standings/cbs_2021_standings.html')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_projection(df):\n",
    "    extract =  [col for col in df.columns if '_adj' in col]\n",
    "    extract = [col for col in ['Avail', 'Player', 'Eligbible', 'playerid'] if col in df.columns] + extract\n",
    "    df = df[extract].rename(columns={k: re.sub('_adj', '', k) for k in extract})\n",
    "    return df\n",
    "\n",
    "hitter_proj = extract_projection(full_hitters).fillna({'Eligible': 'U'})\n",
    "print(hitter_proj.PA.isna().sum())\n",
    "hitter_proj = hitter_proj.merge(elig[['Player', 'Eligible']],  how='left', on='Player').fillna({'Eligible': 'U'})\n",
    "hitter_proj.isna().sum()\n",
    "#hitter_proj[hitter_proj.Eligible.isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitter_proj['fwar'] = valuator.valuate_hitters(hitter_proj, 16*12)\n",
    "\n",
    "pitcher_proj = extract_projection(full_pitchers)\n",
    "pitcher_proj['ERA'] = pitcher_proj.ER / pitcher_proj.IP * 9\n",
    "pitcher_proj['fwar'] = valuator.valuate_pitchers(pitcher_proj, 16*12)\n",
    "\n",
    "hitter_proj.sort_values('fwar', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitter_proj.to_csv('local/hitter_proj.csv', index_label='index')\n",
    "pitcher_proj.to_csv('local/pitcher_proj.csv', index_label='index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Unfound Players\n",
    "\n",
    "Everything above is solid. WIP stuff to find more player ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "france = unfound_hitters.loc[93, 'Player'] # in hitter_ids\n",
    "cbs_player_col_to_df(unfound_hitters.Player)#.merge()\n",
    "cbseam = cbs_player_col_to_df(cbs22.Player).Team.fillna('---').unique().tolist()\n",
    "teams = list(zip(\n",
    "    sorted(cbseam),\n",
    "    sorted(fg22.Team.unique().tolist())\n",
    "))\n",
    "{b: a for a, b in teams if a != b}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02ee4401c5460a4ee3bc94108cf95546c8e39c298a8555b54bdd3e60e7d4869e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
